---
title: "Assignment1"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Assignment 1
Jop Keuning 11014407, Nienke Deutz 2732866 and Harshita Choudhary 13807609

##Exercise1


#1a
First of we check the data for normality which is done in two ways, first with a qqplot which shows that normality is present.
```{r}
waiting_times <- c(5.4, 17.9, 19.0, 0.5, 15.9, 2.7, 6.2, 2.5, 4.7, 6.9, 10.8, 24.3, 5.6, 23.0, 10.7)
mu <- mean(waiting_times)
sigma <- sd(waiting_times)
qqnorm(waiting_times)

```

But to be extra sure that normality is indeed the case a shapiro test will confirm it as indeed fufilling the normality condition
```{r}
shapiro.test(waiting_times)
```
Now that normality has been confirmed it is time to construct a confidence interval for the mu at 97% for which alpha needs to be set at 0.05. With this the confidence interval and the minimum sample size can be found.

To calculate the confidence interval we take the mean of the data we take upper quantile of the normal distribution as za with the upper quantile taken defined as 1-alpha. With this the confidence is calculated as $mean - (za/2)*sd/squareroot(n) as the lower bound and mean + (za/2)*sd/squareroot(n)$ where n is the sample size set at 10, mean is the average of the data and sd the standard deviation

```{r}
n <- length(waiting_times)

alpha <- 0.015
za <- qnorm(1-alpha)
ci <- c(mu -(za/2)*(sigma/sqrt(n)), mu + (za/2)*(sigma/sqrt(n)))
print(ci)

```
To calculate the minimum sample size needed to attain this confidence interval a $za$ value of the normal distribution of $1-alpha/2$ is needed. With this the calculation of the minimum number of samples is as follows: $n_min = (za^2*sd^2)/E$. Here E signifies the error and the the confidence interval will have a length of at most 2E. As we want the length to be at most 2 we can set E equal to 1 resulting in the followint minimum number of samples

```{r}
za2 <- qnorm(1-alpha/2)
n_minimum <- (za2^2*sigma^2)/1
print(n_minimum)
```
Finally we want to compare the previously calculated confidence interval with a bootstrapped one. The code for this bootstrap and it's result can be seen below.

```{r}

B = 1000
Tstar = numeric(B)
for(i in 1:B){
  Xstar <- sample(waiting_times, replace = TRUE)
  Tstar[i] <- mean(Xstar)}
Tstar015 <- quantile(Tstar, 0.015)
Tstar985 <- quantile(Tstar, 0.985)
sum(Tstar <Tstar015)
boodstrap <- c(2*mu-Tstar985,2*mu-Tstar015)
print(boodstrap)
```
When compared to the confidence interval calculated above which looks like this, (8.23295 12.58038) we can see that the bootstrap confidence interval is wider than that of the calculated one by a difference of around 2 in both bounds.






#1b
To verify the doctor's claim we perform both a t-test and a sign test for a mean less than 15. From the t-test we can see that the mean lies below 13.94 with a confidence interval of 95%. With the sign test we get a probability range of 0.69 to 1 with the confidence interval of 95% meaning we can say that for both tests the doctor's claim that the waiting time is less than 15 minutes on average is correct.
```{r}
ttest = t.test(waiting_times,mu=15,alt="less")
print(ttest)
n = 10
binom.test(sum(waiting_times<15), n)
```


1c.

To compute the power of the t-test and sign test is to use p-value of different samples from the data for a large amount of iterations and calculate the average of all p-values that satisfy the condition of $p_value < 0.05$, meaning all significant p-values. This results in that the sign tests have a power of 1 but in both the cases for mu at 13 and 14 the ttest has a power below 0.5

```{r}
B=1000
n<-length(waiting_times)
psign<-numeric(B)
pttest<-numeric(B)
for(i in 1:B) {
  x = sample(waiting_times, replace = TRUE)
  pttest[i]<-t.test(x, mu=13)[[3]] ## extract p-value
  psign[i]<-binom.test(sum(x=13), n, p=0.5)[[3]]
}
sum(psign<0.05)/B
sum(pttest<0.05)/B

for(i in 1:B) {
  x = sample(waiting_times, replace = TRUE)
  pttest[i]<-t.test(x, mu=14)[[3]] ## extract p-value
  psign[i]<-binom.test(sum(x=14), n, p=0.5)[[3]]
}
sum(psign<0.05)/B
sum(pttest<0.05)/B
```


##Exercise 2



#b

```{r}
clouds <- read.csv("clouds.txt", sep="")
is.data.frame(clouds)
clouds_copy <- data.frame(clouds)
clouds_copy$square_root_seeded ='^'(clouds_copy$seeded,1/2)
clouds_copy$square_root_unseeded ='^'(clouds_copy$unseeded,1/2)
clouds_copy$double_square_root_seeded='^'(clouds_copy$square_root_seeded,1/2)
clouds_copy$double_square_root_unseeded='^'(clouds_copy$square_root_unseeded,1/2)
#View(clouds_copy)

```


Square root of the values: 

```{r Normality Check, echo=FALSE}
# FOR NORMALITY CHECK
hist(clouds_copy[['square_root_seeded']] - clouds_copy[['square_root_unseeded']],main="Square root of seeded - Square root of unseeded")

```
```{r, echo=FALSE}
# FOR NORMALITY CHECK
qqnorm(clouds_copy[['square_root_seeded']]-clouds_copy[['square_root_unseeded']]); qqline(clouds_copy[['square_root_seeded']]-clouds_copy[['square_root_unseeded']])
```

QQ - data deviates at the tail. It doesn't seem to follow a normal distribution. There are a few outliers.


Two Sample T-test:
```{r T-Test, echo=FALSE}
# T-test for two paired samples - root
t.test(clouds_copy[['square_root_seeded']],clouds_copy[['square_root_unseeded']],paired=TRUE)

```
p-value is 0.0127 therefore, H0 is rejected. Hence, nitrate has an effect.

Mann-Whitney Test:
```{r Mann-Whitney Test, echo=FALSE}
## Mann-Whitnney Test
wilcox.test(clouds_copy[['square_root_seeded']],clouds_copy[['square_root_unseeded']])
```
p-value is 0.0138 less than 0.05 therefore, H0 is  rejected. Hence, nitrate has an effect. 

Kolmogorov-Smirnov Test:
```{r Kolmogorov-Smirnov Test, echo=FALSE}
## kolmogorov - smirnov Test
ks.test(clouds_copy[['square_root_seeded']],clouds_copy[['square_root_unseeded']])
# p-value is less than 0.05 therefore, H0  rejected

```
p-value is 0.01905 less than 0.05 therefore, H0 is  rejected. Hence, nitrate has an effect.


Double square root values:

```{r Normality Check Double Root , echo=FALSE}
# FOR NORMALITY CHECK
hist(clouds_copy[['double_square_root_seeded']]-clouds_copy[['double_square_root_unseeded']],main='Seeded - Unseeded')

```
```{r, echo=FALSE}
# FOR NORMALITY CHECK
qqnorm(clouds_copy[['double_square_root_seeded']]-clouds_copy[['double_square_root_unseeded']])
qqline(clouds_copy[['double_square_root_seeded']]-clouds_copy[['double_square_root_unseeded']])
```
QQ : Data deviates at the tails so distribution doesn't seem to be normal.

Two Sample T-Test:
```{r T-test double root, echo=FALSE}
# T-test for two paired samples - double root
t.test(clouds_copy[['double_square_root_seeded']],clouds_copy[['double_square_root_unseeded']],paired=TRUE)
```
p-value is 0.008811 therefore, H0 : no effect of silver nitrate, can be rejected. Hence, nitrate has an effect. 

Mann-Whitnney Test:
```{r Mann-Whitney Test Double Root, echo=FALSE}
## Mann-Whitnney Test
wilcox.test(clouds_copy[['double_square_root_seeded']],clouds_copy[['double_square_root_unseeded']])
```
p-value is 0.01383. Hence, silver nitrate has an effect. 

Kolmogorov - Smirnov Test:
```{r  Kolmogorov-Smirnov Test Double Root, echo=FALSE}
## kolmogorov - smirnov Test
ks.test(clouds_copy[['double_square_root_seeded']],clouds_copy[['double_square_root_unseeded']])

```
p-value is 0.01905. Hence, silver nitrate has an effect. 

Conclusion:
The p-value of two sample T-test is lower when the square root of the data is taken. However, for Mann Whitney and Kolmogorov - Smirnov Test, the p-value doesn't change on taking the square root.


#2c

```{r}
#Calculate the  mean
mean_estimator = mean(clouds$seeded)
std_dev_estimator = sd(clouds$seeded)
n = 26
sqrt(n)
t_0.025 = 2.05954 
c_i_lower = mean_estimator - t_0.025*std_dev_estimator/sqrt(n)
c_i_upper = mean_estimator + t_0.025*std_dev_estimator/sqrt(n)
c_i_lower
c_i_upper

```

```{r}
t.test(clouds[['seeded']],mu = 0)
estimator_lambda = 1/mean_estimator
ci_lower = 1/704.8432
ci_upper = 1/179.1260
estimator_lambda
ci_lower
ci_upper
```
lambda(Estimator) =  0.002262522 and confidence interval is (0.001418755,0.005582662) 

Bootstrap Test:
```{r}
T = median(clouds[['seeded']])
T
B=1000
tstar=numeric(B)
n=26

for (i in 1:B){
  xstar=rexp(n,estimator_lambda)
  tstar[i]=median(xstar)}
hist(tstar)


```

```{r}
pl=sum(tstar<T)/B; pr=sum(tstar>T)/B; p=2*min(pl,pr)
pl;pr;p
```
We get p = 0.266 which is greater than 0.05 therefore, we can't reject the null hypothesis : seeded data belongs to exponential distribution of a rate parameter lambda.

kolmogorov - Smirnov Test:
```{r}
## kolmogorov - smirnov Test
ks.test(x = clouds[['seeded']], y = "pexp", rate = estimator_lambda)
```
We get p = 0.2476 which is greater than 0.05 therefore, we can't reject the null hypothesis : that seeded data belongs to exponential distribution of a rate parameter lambda.


#2d : 
```{r sign test,echo=FALSE}
# Left tailed
# null hypothesis : median >= 300
# Alternate : median < 300
n = 26
x = sum(clouds[['seeded']] < 300 )
x
binom.test(x,n,p=0.5,alt="less")
```
We get a p-value of 0.9622, therefore we can't reject the null hypothesis that the median is greater than or equal to 300. We can say with 95% sugnificance level that the median is not less than 300.

```{r sign test 2, echo=FALSE}
num_less_30 = sum(clouds[['seeded']] < 30 )
n=26
binom.test(num_less_30,n,p=0.25,alternative="less")
```

p-value is 0.08019. Therefore, we reject that at most 25% of seeded clouds have precipitation less than 30 with significance level of 95%.

##exercise 3

```{r Dogs, echo=FALSE}
dogs <- read.csv("dogs.txt", sep="")
is.data.frame(dogs)
```
#3a
```{r , echo=FALSE}
# FOR NORMALITY CHECK
qqnorm(dogs[,1], main="QQ plot for Isofluorane"); qqline(dogs[,1])
```
QQ plot deivaties at the tail. It doesn't seem to follow a normal distribution.
```{r}
shapiro.test(dogs[,1])
```
p-value of shapiro-test is less than 0.05 therefore the claim that it follows a normal distribution is rejected.

```{r}
qqnorm(dogs[,2], main="QQ plot for halothane"); qqline(dogs[,2])

```
Looking at the QQ-plot it is reasonable to say that Halothane data is from a normal distribution.
```{r}
shapiro.test(dogs[,2])
```
shapiro test p-value is greater than 0.05. It follows a normal distribution.

```{r}
qqnorm(dogs[,3],main = "QQ plot for cyclopropane"); qqline(dogs[,3])
```
Very less diviation therefore, we can say that it comes from a normal distribution.

```{r}
shapiro.test(dogs[,3])
```
shapiro test p-value is greater than 0.05. It follows a normal distribution.

#3b 

CORRELATION TEST : 
```{r correlation, echo=FALSE}
## correlation isofluorane and halothane
cor.test(dogs[['isofluorane']],dogs[['halothane']],method="spearman")

```
p value of 0.5 is greater than 0.05 therefore, we can't reject the null hypothesis that there is no linear correlation. Hence, isofluorane and halothane are not linearly correlated.

```{r, echo=FALSE}
qqnorm(dogs[,1]-dogs[,2] , main = "QQ plot for (Isofluorane - Halothane)")
qqline(dogs[,1]-dogs[,2])
```
QQ plot - Very less diviation therefore, we can say that it comes from a normal distribution.

```{r, echo=FALSE}
shapiro.test(dogs[,1]-dogs[,2])
```
shapiro test p-value is 0.8744 which is greater than 0.05. Therefore, the difference in isofluorane and halothane is normally distributed.

Two paired sample T-Test : 
```{r, echo=FALSE}
t.test(dogs[,1],dogs[,2],paired=TRUE)
```
p value of 0.7145 is more than 0.05, therefore there is no difference between the effect of isofluorane and halothane. Distribution of these columns are not significantly different.

PERMUTATION TEST:
 
```{r permuttaion test}
boxplot(dogs[,1],dogs[,2],names=c("isoflurane","halothane"))

```
```{r}
mystat=function(x,y) {mean(x-y)}
B=1000; tstar=numeric(B)
for (i in 1:B) {
  dogstar=t(apply(cbind(dogs[,1],dogs[,2]),1,sample))
  tstar[i]=mystat(dogstar[,1],dogstar[,2]) }

myt=mystat(dogs[,1],dogs[,2])
#myt
hist(tstar)

```
```{r}
pl=sum(tstar<myt)/B
pr=sum(tstar>myt)/B
p=2*min(pl,pr)
p
```
p value of 0.63 is more than 0.05, therefore there is no difference between the effect of isofluorane and halothane. Distribution of these columns are not significantly different

Permutation test for two-paired samples is valid here and it doesn't depend on the distribution of data. Here, T-test will perform better than the permutation test because data of difference in isofluorane and halothane is normally distributed. 

#3c
One - way ANOVA: 
```{r, echo=FALSE}
dogsframe=data.frame(yield=as.vector(as.matrix(dogs)),variety=factor(rep(1:3,each=10)))

is.factor(dogsframe$variety); is.numeric(dogsframe$variety)

dogsanova=lm(yield~variety,data=dogsframe)
anova(dogsanova)
```
The p-value  0.011, hence HA : μ1 = μ2 = μ3 is is rejected with 95% significance level. Therefore, the type of drug has an effect on the concentration of plasma epinephrine.

```{r}
qqnorm(residuals(dogsanova),main = "QQ plot of estimated erros") 
```
QQ plot of residuals eik = Yik − μi (k = 1 to 10 and i = 1 to 3 ) looks close to a normal distribution.
```{r}
plot(fitted(dogsanova),residuals(dogsanova))
```
The plot of fitted(group means) against residuals show no pattern.

Therefore, assumptions for one-way ANOVA hold true.

Estimated concentrations of epinephrine for different drugs:
```{r, echo=FALSE}

#isoflurane
mean(dogs[,1])
#halothane
mean(dogs[,2])
#cyclopropane
mean(dogs[,3])

```
Estimated average concentrations of epinephrine for isoflurane, halothane and cyclopropane are 0.434,0.469 and 0.853 respectively.


#3d
Krushal-Wallis Test:
```{r, echo=FALSE}
kruskal.test(yield~variety,data=dogsframe)
```

p-value for krushal-wallis test comes out to be 0.05948. Therefore, HA:  μ1 = μ2 = μ3 can't be rejected. The type of drug has no effect on the concentration of plasma epinephrine.


Conclusion - The reliability of ANOVA test depends on the assumption that the data comes from a normal dsitribution. Whereas, Krushal-Wallis Test is a non-paramteric test and doesn't depedent on the distribution of data.
For the above data ANOVA test and Krushal-Wallis Test arrive at different conclusions. ANOVA test accepts that the type of drug has an effect on the  concentration of plasma epinephrine whereas Krushal-Wallis test rejects this claim.
The above data follows a normal distribution therefore, the result of one-way ANOVA is more reliable than Krushal-Wallis Test. 


##exercise 5

#5a
```{r}
cream <- read.csv("cream.txt", sep="")
is.vector(cream$acidity)

cream$batch = as.factor(cream$batch)
cream$position = as.factor(cream$position)
cream$starter = as.factor(cream$starter)

creamanov = lm(acidity~batch+position+starter,data=cream)
anova(creamanov)
summary(creamanov)
```
From the three way experiment above we can see that there is a difference between the effects of different starter values on the acidity in the column $Pr(>|t|)$ which shows that there is a difference between starter1 and 2 of 0.0579 which is slightly larger than 0.05 which is generally used as the cutoff for significant effects. This means that there is a large difference between starter1 which is very significant and starter2 which is barely significant. 




#5b
From the test results seen above in the subsection for 5a we can see that all the values for the position are above the 0.05 cutoff of significance meaning it has no real significance on the acidity and can be left out from the test which will look like the results below.
```{r}
creamanov = lm(acidity~batch+starter,data=cream)
anova(creamanov)
summary(creamanov)
```

#5c 
The friedman test can be used to test if none of the the factors have an effect on the acidity and so we only need to run it if we are not sure any of the factors have ann effect and is good to do just in case. The result of the Friedman test can be seen here.
```{r}
friedman.test(cream$acidity, cream$batch, cream$starter,data=cream)
```
From this we can see that with a p-value 0.0107 the H0 hypothesis that there is no effect on the acidity is rejected.

#5d
```{r}
library(lme4)
creamlmer = lmer(acidity~(1|batch)+starter,data=cream, REML=FALSE)
summary(creamlmer)
creamlmer1 = lmer(acidity~(1|batch),data=cream, REML=FALSE)
anova(creamlmer, creamlmer1)
```
From the summary of the mixed effect analysis we can see in the $Pr(>Chisq)$ column of the anova test, which can in effect be viewed as the p-value of the starter factor sits at a very low value of 3.339e-07 making it very significant. When compared to the p-value of the anova test in section 5b which had a p-value of 4.816e-06 for the starter factor the difference is there but it is very minor with the mixed effect analysis achieving a slightly lower p-value